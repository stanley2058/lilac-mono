# Logging
LOG_LEVEL=
# Local logger output format
#LILAC_LOG_JSONL=
# In JSONL mode, keep stdout/stderr split instead of unified stdout
#LILAC_LOG_JSONL_SPLIT_STREAMS=

# Optional: mirror logs to OpenObserve (JSON array ingestion endpoint)
#LILAC_LOG_OPENOBSERVE_BASE_URL=
#LILAC_LOG_OPENOBSERVE_ORG=
#LILAC_LOG_OPENOBSERVE_STREAM=
# Optional separate level for OpenObserve sink (debug|info|warn|error|fatal)
#LILAC_LOG_OPENOBSERVE_LEVEL=
# Auth precedence: bearer token first, then username/password basic auth
#LILAC_LOG_OPENOBSERVE_BEARER_TOKEN=
#LILAC_LOG_OPENOBSERVE_USERNAME=
#LILAC_LOG_OPENOBSERVE_PASSWORD=

# Bot token
DISCORD_TOKEN=

# Storage
REDIS_URL=
SQLITE_URL=
DATA_DIR=
LILAC_WORKSPACE_DIR=

# Package manager (optional, for persisted global installs)
BUN_INSTALL_GLOBAL_DIR=
BUN_INSTALL_BIN=
BUN_INSTALL_CACHE_DIR=
NPM_CONFIG_PREFIX=
XDG_CONFIG_HOME=

# Tool server
LL_TOOL_SERVER_PORT=

# Provider: OpenAI
OPENAI_BASE_URL=
OPENAI_API_KEY=
# OpenAI Responses transport: sse | auto | websocket
OPENAI_RESPONSES_TRANSPORT=

# Provider: Codex (chatgpt.com backend)
# Codex Responses transport: sse | auto | websocket
CODEX_RESPONSES_TRANSPORT=

# Debug: LLM wire traces (JSONL)
# Captures request/response headers/body previews and SSE events for OpenAI/Codex fetches.
# LILAC_LLM_WIRE_DEBUG=1
# LILAC_LLM_WIRE_DEBUG_DIR=/data/debug/llm-wire
# LILAC_LLM_WIRE_DEBUG_MAX_BODY_BYTES=65536
# LILAC_LLM_WIRE_DEBUG_MAX_EVENTS=400

# Provider: OpenAI-compatible
OPENAI_COMPATIBLE_BASE_URL=
OPENAI_COMPATIBLE_API_KEY=

# Provider: xAI
XAI_BASE_URL=
XAI_API_KEY=

# Provider: Anthropic
ANTHROPIC_BASE_URL=
ANTHROPIC_API_KEY=

# Provider: OpenRouter
OPENROUTER_BASE_URL=
OPENROUTER_API_KEY=

# Provider: Groq
GROQ_BASE_URL=
GROQ_API_KEY=

# Provider: Google / Gemini (any of these work)
GEMINI_BASE_URL=
GOOGLE_BASE_URL=
GEMINI_API_KEY=
GOOGLE_API_KEY=
GOOGLE_GENERATIVE_AI_API_KEY=

# Provider: Vercel AI Gateway
AI_GATEWAY_BASE_URL=
AI_GATEWAY_API_KEY=

# Tools: web
EXA_API_BASE_URL=
EXA_API_KEY=
TAVILY_API_KEY=
TAVILY_API_BASE_URL=
